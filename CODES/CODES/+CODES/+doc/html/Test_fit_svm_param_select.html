
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Examples / Meta-models / svm (parameters selection)</title><meta name="generator" content="MATLAB 8.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2015-06-23"><meta name="DC.source" content="Test_fit_svm_param_select.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1><a href="demo.html">Examples</a> / <a href="demo_fit.html">Meta-models</a> / svm (parameters selection)</h1><!--introduction--><p>This file shows different parameter selection techniques and how they pertain to the choice of kernel parameters</p><p>
  <style type="text/css">
    span.string{color:#A020F0;font-family:monospace;}
    p{text-align: justify;}
  </style>
</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Documentation</a></li><li><a href="#2">Set rng</a></li><li><a href="#3">Concept</a></li><li><a href="#4">Simple 2D problem</a></li><li><a href="#7">Parameter selection strategy</a></li><li><a href="#8">References</a></li></ul></div><h2>Documentation<a name="1"></a></h2><p>The documentation for the <tt>svm</tt> class can be found <a href="svm.html">here</a>.</p><h2>Set rng<a name="2"></a></h2><p>Set random number generator seed:</p><pre class="codeinput">rng(0)
</pre><h2>Concept<a name="3"></a></h2><p>When training a meta-model, one typically tries to do so such that it minimizes some metrics. In classification problems, that metric is often the generalization error, i.e., the integral of the misclassification over the domain</p><p><img src="Test_fit_svm_param_select_eq09586939721533559355.png" alt="$$err_{gen}=\int\mathcal{I}_{l(\mathbf{x})\neq \hat{l}(\mathbf{x})}\mathrm d\mathbf{x}$$"></p><p>where <img src="Test_fit_svm_param_select_eq16100408703506573127.png" alt="$l(\mathbf{x})$"> is the true class and <img src="Test_fit_svm_param_select_eq13348251826115144186.png" alt="$\hat{l}(\mathbf{x})$"> is the estimated class of <img src="Test_fit_svm_param_select_eq08291690262771002032.png" alt="$\mathbf{x}$">. One can show that a Leave One Out (LOO) procedure yields an almost unbiased estimator of the generalization error, <a href="#ref_loo">Luntz and Brailovsky (1969)</a>. However, an LOO procedure may be numerically intractable. A Cross-Validation (CV), typically 10-fold, is usually faster and preferred as it is an estimator of the LOO error.</p><p>Specifically for Support Vector Machine, <a href="#ref_vap">Vapnik (2000)</a> drew a link between the number of support vectors and the generalization capability of the model. Later on, <a href="#ref_cha">Chapelle et al. (2002)</a> develeped an estimate of the LOO error based on the span of the support vectors.</p><p>In certain cases, such as highly unbalanced data, the generalization error is ill defined and the balanced generalization error makes more sense, <a href="#ref_peng">Jiang and Missoum (2014)</a>. The Area Under the Curve (AUC), <a href="#ref_AUC">Metz (1978)</a>, is also widely used.</p><p>Finally, over the years, heuristics have been developed to quickly
guess a suitable value for the kernel parameters. Such heuristics can be
cross kernel or kernel specific. The heuristic referred to as <span
class='string'>'stiffest'</span> look for the most general case such that
there is no misclassification error <a href=#ref_bas>(Basudhar and
Missoum, 2010)</a>. The heuristic referred to as <span id="jaakkola_ref"
class='string'>'fast'</span>, defined for the Gaussian kernel, defines
the kernel parameter as the mean of the pairwise distances between +1 and
-1 samples <a href=#ref_jaakkola>(Jaakkola et al.,
1999)</a>.</p><h2>Simple 2D problem<a name="4"></a></h2><p>Consider a simple 2D classification problem:</p><pre class="codeinput">f=@(x)x(:,2)-sin(10*x(:,1))/4-0.2;
x=CODES.sampling.cvt(200,2);
y=f(x);
[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);
figure(<span class="string">'Position'</span>,[200 200 500 500])
contour(X,Y,Z,[0 0],<span class="string">'k'</span>)
hold <span class="string">on</span>
plot(x(y&lt;=0,1),x(y&lt;=0,2),<span class="string">'ro'</span>)
plot(x(y&gt;0,1),x(y&gt;0,2),<span class="string">'bo'</span>)
axis <span class="string">equal</span>
</pre><img vspace="5" hspace="5" src="Test_fit_svm_param_select_01.png" alt=""> <p>For varying <tt>theta</tt>, train an SVM and compare the different aforementioned metrics:</p><pre class="codeinput">svm=CODES.fit.svm(x,y);
[theta_lb,theta_ub,theta_mean]=svm.point_dist;  <span class="comment">% Pairwise distances between +1 and -1 samples</span>
thetas=linspace(theta_lb,theta_ub,20)';
loo=zeros(length(thetas),2);
cv=loo;Nsv=loo;chapelle=loo;auc=loo;
true_misc=loo;                               <span class="comment">% True misclassification</span>
X_t=[X(:) Y(:)];
Y_t=Z(:);

<span class="keyword">parfor</span> i=1:length(thetas)
    svm_tmp=CODES.fit.svm(x,y,<span class="string">'theta'</span>,thetas(i),<span class="string">'C'</span>,1e4);
    loo(i,:)=[svm_tmp.loo svm_tmp.loo(<span class="string">'use_balanced'</span>,true)];
    cv(i,:)=[svm_tmp.cv svm_tmp.cv(<span class="string">'use_balanced'</span>,true)];
    Nsv(i,:)=[svm_tmp.N_sv_ratio svm_tmp.N_sv_ratio(true)];
    chapelle(i,:)=[svm_tmp.chapelle svm_tmp.chapelle(true)];
    auc(i,:)=100-[svm_tmp.auc(svm_tmp.X,svm_tmp.Y) svm_tmp.cv(<span class="string">'metric'</span>,<span class="string">'AUC'</span>)];
    true_misc(i,:)=[svm_tmp.me(X_t,Y_t) svm_tmp.me(X_t,Y_t)];
<span class="keyword">end</span>
</pre><p>Plot a comparison of these metrics:</p><pre class="codeinput">figure(<span class="string">'Position'</span>,[200 200 750 500])
plot(thetas,true_misc(:,1),<span class="string">'k-.'</span>)
hold <span class="string">on</span>
plot(thetas,loo(:,1),<span class="string">'r-'</span>)
plot(thetas,cv(:,1),<span class="string">'b-'</span>)
plot(thetas,Nsv(:,1),<span class="string">'c-'</span>)
plot(thetas,chapelle(:,1),<span class="string">'m-'</span>)
plot([theta_mean theta_mean],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'k--'</span>)
plot([theta_lb theta_lb],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'g--'</span>)
plot([theta_ub theta_ub],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'g--'</span>)
leg=legend(<span class="string">'True'</span>,<span class="string">'loo'</span>,<span class="string">'cv'</span>,<span class="string">'Nsv'</span>,<span class="string">'Chapelle'</span>,<span class="string">'Fast'</span>,<span class="string">'Location'</span>,<span class="string">'bestoutside'</span>);
set(leg,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)
set(gca,<span class="string">'xscale'</span>,<span class="string">'log'</span>)
axis([0.99*theta_lb 1.01*theta_ub 0 40])
xlabel(<span class="string">'$\theta$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)
ylabel(<span class="string">'$err_{gen}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)

figure(<span class="string">'Position'</span>,[200 200 750 500])
plot(thetas,true_misc(:,2),<span class="string">'k-.'</span>)
hold <span class="string">on</span>
plot(thetas,loo(:,2),<span class="string">'r-'</span>)
plot(thetas,cv(:,2),<span class="string">'b-'</span>)
plot(thetas,Nsv(:,2),<span class="string">'c-'</span>)
plot(thetas,chapelle(:,2),<span class="string">'m-'</span>)
plot(thetas,auc(:,1),<span class="string">'g-'</span>)
plot(thetas,auc(:,2),<span class="string">'g--'</span>)
plot([theta_mean theta_mean],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'k--'</span>)
plot([theta_lb theta_lb],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'g--'</span>)
plot([theta_ub theta_ub],[0 max(max([loo;cv;Nsv;chapelle]))],<span class="string">'g--'</span>)
leg=legend(<span class="string">'True (bal)'</span>,<span class="string">'loo (bal)'</span>,<span class="string">'cv (bal)'</span>,<span class="string">'Nsv (bal)'</span>,<span class="string">'Chapelle (bal)'</span>,<span class="string">'AUC'</span>,<span class="string">'AUC (CV)'</span>,<span class="string">'Fast'</span>,<span class="string">'Location'</span>,<span class="string">'bestoutside'</span>);
set(leg,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)
set(gca,<span class="string">'xscale'</span>,<span class="string">'log'</span>)
axis([0.99*theta_lb 1.01*theta_ub 0 40])
xlabel(<span class="string">'$\theta$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)
ylabel(<span class="string">'$err_{gen}^{bal}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'FontSize'</span>,20)
</pre><img vspace="5" hspace="5" src="Test_fit_svm_param_select_02.png" alt=""> <img vspace="5" hspace="5" src="Test_fit_svm_param_select_03.png" alt=""> <h2>Parameter selection strategy<a name="7"></a></h2><p>Train different SVMs using different metrics and compare them:</p><pre class="codeinput">f=@(x)x(:,2)-sin(10*x(:,1))/4-0.5;
x=CODES.sampling.cvt(200,2);
y=f(x);

[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);

tic;svm=CODES.fit.svm(x,y);time_fast=toc;
fast_err=svm.me([X(:) Y(:)],Z(:));
tic;svm1=CODES.fit.svm(x,y,<span class="string">'param_select'</span>,<span class="string">'loo'</span>,<span class="string">'UseParallel'</span>,true);time_loo=toc;
loo_err=svm1.me([X(:) Y(:)],Z(:));
tic;svm2=CODES.fit.svm(x,y,<span class="string">'param_select'</span>,<span class="string">'chapelle'</span>);time_chapelle=toc;
chapelle_err=svm2.me([X(:) Y(:)],Z(:));
tic;svm3=CODES.fit.svm(x,y,<span class="string">'param_select'</span>,<span class="string">'auc'</span>);time_auc=toc;
auc_err=svm3.me([X(:) Y(:)],Z(:));

disp([<span class="string">'Using fast,     theta='</span> num2str(svm.theta,<span class="string">'%5.3e'</span>) <span class="string">', C='</span> num2str(svm.C,<span class="string">'%5.3e'</span>) <span class="string">', err_gen='</span> num2str(fast_err,<span class="string">'%5.2f'</span>) <span class="string">'%, time='</span> CODES.common.time(time_fast)])
disp([<span class="string">'Using loo,      theta='</span> num2str(svm1.theta,<span class="string">'%5.3e'</span>) <span class="string">', C='</span> num2str(svm1.C,<span class="string">'%5.3e'</span>) <span class="string">', err_gen='</span> num2str(loo_err,<span class="string">'%5.2f'</span>) <span class="string">'%, time='</span> CODES.common.time(time_loo)])
disp([<span class="string">'Using chapelle, theta='</span> num2str(svm2.theta,<span class="string">'%5.3e'</span>) <span class="string">', C='</span> num2str(svm2.C,<span class="string">'%5.3e'</span>) <span class="string">', err_gen='</span> num2str(chapelle_err,<span class="string">'%5.2f'</span>) <span class="string">'%, time='</span> CODES.common.time(time_chapelle)])
disp([<span class="string">'Using auc,      theta='</span> num2str(svm3.theta,<span class="string">'%5.3e'</span>) <span class="string">', C='</span> num2str(svm3.C,<span class="string">'%5.3e'</span>) <span class="string">', err_gen='</span> num2str(auc_err,<span class="string">'%5.2f'</span>) <span class="string">'%, time='</span> CODES.common.time(time_auc)])

[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);
figure(<span class="string">'Position'</span>,[200 200 500 500])
contour(X,Y,Z,[0 0],<span class="string">'k'</span>)
hold <span class="string">on</span>
svm.isoplot(<span class="string">'legend'</span>,false,<span class="string">'samples'</span>,false,<span class="string">'sv'</span>,false,<span class="string">'bcol'</span>,<span class="string">'r'</span>)
svm1.isoplot(<span class="string">'legend'</span>,false,<span class="string">'samples'</span>,false,<span class="string">'sv'</span>,false,<span class="string">'bcol'</span>,<span class="string">'b'</span>)
svm2.isoplot(<span class="string">'legend'</span>,false,<span class="string">'samples'</span>,false,<span class="string">'sv'</span>,false,<span class="string">'bcol'</span>,<span class="string">'m'</span>)
svm3.isoplot(<span class="string">'legend'</span>,false,<span class="string">'samples'</span>,false,<span class="string">'sv'</span>,false,<span class="string">'bcol'</span>,<span class="string">'g'</span>)
legend(<span class="string">'True'</span>,<span class="string">'fast'</span>,<span class="string">'loo'</span>,<span class="string">'chapelle'</span>,<span class="string">'auc'</span>)
</pre><pre class="codeoutput">Using fast,     theta=6.501e-01, C=1.000e+04, err_gen=2.90%, time=5.9445e-02 s
Using loo,      theta=2.298e-01, C=1.000e+02, err_gen=2.56%, time=43s
Using chapelle, theta=3.545e-01, C=1.000e+02, err_gen=2.98%, time=3s
Using auc,      theta=3.250e-01, C=1.000e+02, err_gen=3.05%, time=3s
</pre><img vspace="5" hspace="5" src="Test_fit_svm_param_select_04.png" alt=""> <h2>References<a name="8"></a></h2><p><ul style="list-style-type:none">
  <li id="ref_loo"><span style="color:#005fce;">Luntz and Brailovsky
  (1969)</span>: Luntz A., Brailovsky V., (1969) <i>On estimation of
  characters obtained in statistical procedure of recognition</i>.
  Technicheskaya Kibernetica 3(6):6-12</li>
  <li id="ref_auc"><span style="color:#005fce;">Metz (1978)</span>: Metz
  C. E., (1978) <i>Basic principles of ROC analysis. Seminars in Nuclear
  Medicine</i>. Technicheskaya Kibernetica 8(4):283-298 - <a
  href="http://dx.doi.org/10.1016/S0001-2998(78)80014-2">DOI</a></li>
  <li id="ref_jaakkola"><span style="color:#005fce;">Jaakkola et al.
  (1999)</span>: Jaakkola T., Diekhans M., Haussler D., (1999)
  <i>Using the Fisher kernel method to detect remote protein
  homologies</i>. In: International Conference on Intelligent Systems for
  Molecular Biology. 149-158 - <a
  href="http://www.ncbi.nlm.nih.gov/pubmed/10786297">PMID</a></li>
  <li id="ref_vap"><span style="color:#005fce;">Vapnik (2000)</span>:
  Vapnik V., (2000) <i>The nature of statistical learning theory</i>.
  Springer</li>
  <li id="ref_cha"><span style="color:#005fce;">Chapelle et al.
  (2002)</span>: Chapelle O., Vapnik V., Bousquet O., Mukherjee S.,
  (2002) <i>Choosing multiple parameters for support vector machines</i>.
  Machine Learning 46(1-3):131-159 - <a
  href="http://dx.doi.org/10.1023/A:1012450327387">DOI</a></li>
  <li id="ref_bas"><span style="color:#005fce;">Basudhar and Missoum
  (2010)</span>: Basudhar A., Missoum S., (2010) <i>An improved adaptive
  sampling scheme for the construction of explicit boundaries</i>.
  Structural and Multidisciplinary Optimization 42(4):517-529 - <a
  href="http://dx.doi.org/10.1007/s00158-010-0511-0">DOI</a></li>
  <li id="ref_peng"><span style="color:#005fce;">Jiang and Missoum
  (2014)</span>: Jiang P., Missoum S., (2014) <i>Optimal SVM parameter
  selection for non-separable and unbalanced datasets</i>. Structural and
  Multidisciplinary Optimization 50(4):523-535 - <a
  href="http://dx.doi.org/10.1007/s00158-014-1105-z">DOI</a></li>
</ul></p><p>Copyright &copy; 2015 Computational Optimal Design of Engineering Systems
(CODES) Laboratory. University of Arizona.</p><p><table style="border: none">
  <tr style="border: none">
    <td style="border: none;padding-left: 0px;">
      <a href ="http://codes.arizona.edu/"><img style="height: 50px;" src ="CODES_logo.png"></a>
    </td><td style="border: none; vertical-align: middle;padding-left: 10px;">
      <a href ="http://codes.arizona.edu/"><span style="font-weight:bold;font-family:Arial;font-size: 20px;color: #002147"><span style="color: #AB0520;">C</span>omputational <span style="color: #AB0520;">O</span>ptimal <span style="color: #AB0520;">D</span>esign of<br><span style="color: #AB0520;">E</span>ngineering <span style="color: #AB0520;">S</span>ystems</span></a>
    </td><td style="border: none;padding-right: 0px;">
      <a href = "http://www.arizona.edu/"><img style="height: 50px;" src = "AZlogo.png"></a>
    </td>
  </tr>
</table></p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2014b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% <demo.html Examples> / <demo_fit.html Meta-models> / svm (parameters selection)
% This file shows different parameter selection techniques and how they
% pertain to the choice of kernel parameters
%
% <html>
%   <style type="text/css">
%     span.string{color:#A020F0;font-family:monospace;}
%     p{text-align: justify;}
%   </style>
% </html>
%
%% Documentation
% The documentation for the |svm| class can be found <svm.html here>.
%
%% Set rng
% Set random number generator seed:
rng(0)

%% Concept
% When training a meta-model, one typically tries to do so such that it
% minimizes some metrics. In classification problems, that metric is often
% the generalization error, i.e., the integral of the
% misclassification over the domain
%
% $$err_{gen}=\int\mathcal{I}_{l(\mathbf{x})\neq \hat{l}(\mathbf{x})}\mathrm d\mathbf{x}$$
%
% where $l(\mathbf{x})$ is the true class and $\hat{l}(\mathbf{x})$ is the
% estimated class of $\mathbf{x}$. One can show that a Leave One Out (LOO)
% procedure yields an almost unbiased estimator of the generalization
% error, <#ref_loo Luntz and Brailovsky (1969)>. However, an LOO procedure
% may be numerically intractable. A Cross-Validation (CV), typically
% 10-fold, is usually faster and preferred as it is an estimator of the LOO
% error.
%
% Specifically for Support Vector Machine, <#ref_vap Vapnik (2000)> drew a
% link between the number of support vectors and the generalization
% capability of the model. Later on, <#ref_cha Chapelle et al. (2002)>
% develeped an estimate of the LOO error based on the span of the support
% vectors.
%
% In certain cases, such as highly unbalanced data, the generalization
% error is ill defined and the balanced generalization error makes more
% sense, <#ref_peng Jiang and Missoum (2014)>. The Area Under the Curve
% (AUC), <#ref_AUC Metz (1978)>, is also widely used.
%
% <html>Finally, over the years, heuristics have been developed to quickly
% guess a suitable value for the kernel parameters. Such heuristics can be
% cross kernel or kernel specific. The heuristic referred to as <span
% class='string'>'stiffest'</span> look for the most general case such that
% there is no misclassification error <a href=#ref_bas>(Basudhar and
% Missoum, 2010)</a>. The heuristic referred to as <span id="jaakkola_ref"
% class='string'>'fast'</span>, defined for the Gaussian kernel, defines 
% the kernel parameter as the mean of the pairwise distances between +1 and
% -1 samples <a href=#ref_jaakkola>(Jaakkola et al.,
% 1999)</a>.</html>
%
%% Simple 2D problem
% Consider a simple 2D classification problem:
f=@(x)x(:,2)-sin(10*x(:,1))/4-0.2;
x=CODES.sampling.cvt(200,2);
y=f(x);
[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);
figure('Position',[200 200 500 500])
contour(X,Y,Z,[0 0],'k')
hold on
plot(x(y<=0,1),x(y<=0,2),'ro')
plot(x(y>0,1),x(y>0,2),'bo')
axis equal

%%
% For varying |theta|, train an SVM and compare the different
% aforementioned metrics:

svm=CODES.fit.svm(x,y);
[theta_lb,theta_ub,theta_mean]=svm.point_dist;  % Pairwise distances between +1 and -1 samples
thetas=linspace(theta_lb,theta_ub,20)';
loo=zeros(length(thetas),2);
cv=loo;Nsv=loo;chapelle=loo;auc=loo;
true_misc=loo;                               % True misclassification
X_t=[X(:) Y(:)];
Y_t=Z(:);

parfor i=1:length(thetas)
    svm_tmp=CODES.fit.svm(x,y,'theta',thetas(i),'C',1e4);
    loo(i,:)=[svm_tmp.loo svm_tmp.loo('use_balanced',true)];
    cv(i,:)=[svm_tmp.cv svm_tmp.cv('use_balanced',true)];
    Nsv(i,:)=[svm_tmp.N_sv_ratio svm_tmp.N_sv_ratio(true)];
    chapelle(i,:)=[svm_tmp.chapelle svm_tmp.chapelle(true)];
    auc(i,:)=100-[svm_tmp.auc(svm_tmp.X,svm_tmp.Y) svm_tmp.cv('metric','AUC')];
    true_misc(i,:)=[svm_tmp.me(X_t,Y_t) svm_tmp.me(X_t,Y_t)];
end
%%
% Plot a comparison of these metrics:

figure('Position',[200 200 750 500])
plot(thetas,true_misc(:,1),'k-.')
hold on
plot(thetas,loo(:,1),'r-')
plot(thetas,cv(:,1),'b-')
plot(thetas,Nsv(:,1),'c-')
plot(thetas,chapelle(:,1),'m-')
plot([theta_mean theta_mean],[0 max(max([loo;cv;Nsv;chapelle]))],'kREPLACE_WITH_DASH_DASH')
plot([theta_lb theta_lb],[0 max(max([loo;cv;Nsv;chapelle]))],'gREPLACE_WITH_DASH_DASH')
plot([theta_ub theta_ub],[0 max(max([loo;cv;Nsv;chapelle]))],'gREPLACE_WITH_DASH_DASH')
leg=legend('True','loo','cv','Nsv','Chapelle','Fast','Location','bestoutside');
set(leg,'interpreter','latex','FontSize',20)
set(gca,'xscale','log')
axis([0.99*theta_lb 1.01*theta_ub 0 40])
xlabel('$\theta$','interpreter','latex','FontSize',20)
ylabel('$err_{gen}$','interpreter','latex','FontSize',20)

figure('Position',[200 200 750 500])
plot(thetas,true_misc(:,2),'k-.')
hold on
plot(thetas,loo(:,2),'r-')
plot(thetas,cv(:,2),'b-')
plot(thetas,Nsv(:,2),'c-')
plot(thetas,chapelle(:,2),'m-')
plot(thetas,auc(:,1),'g-')
plot(thetas,auc(:,2),'gREPLACE_WITH_DASH_DASH')
plot([theta_mean theta_mean],[0 max(max([loo;cv;Nsv;chapelle]))],'kREPLACE_WITH_DASH_DASH')
plot([theta_lb theta_lb],[0 max(max([loo;cv;Nsv;chapelle]))],'gREPLACE_WITH_DASH_DASH')
plot([theta_ub theta_ub],[0 max(max([loo;cv;Nsv;chapelle]))],'gREPLACE_WITH_DASH_DASH')
leg=legend('True (bal)','loo (bal)','cv (bal)','Nsv (bal)','Chapelle (bal)','AUC','AUC (CV)','Fast','Location','bestoutside');
set(leg,'interpreter','latex','FontSize',20)
set(gca,'xscale','log')
axis([0.99*theta_lb 1.01*theta_ub 0 40])
xlabel('$\theta$','interpreter','latex','FontSize',20)
ylabel('$err_{gen}^{bal}$','interpreter','latex','FontSize',20)

%% Parameter selection strategy
% Train different SVMs using different metrics and compare them:

f=@(x)x(:,2)-sin(10*x(:,1))/4-0.5;
x=CODES.sampling.cvt(200,2);
y=f(x);

[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);

tic;svm=CODES.fit.svm(x,y);time_fast=toc;
fast_err=svm.me([X(:) Y(:)],Z(:));
tic;svm1=CODES.fit.svm(x,y,'param_select','loo','UseParallel',true);time_loo=toc;
loo_err=svm1.me([X(:) Y(:)],Z(:));
tic;svm2=CODES.fit.svm(x,y,'param_select','chapelle');time_chapelle=toc;
chapelle_err=svm2.me([X(:) Y(:)],Z(:));
tic;svm3=CODES.fit.svm(x,y,'param_select','auc');time_auc=toc;
auc_err=svm3.me([X(:) Y(:)],Z(:));

disp(['Using fast,     theta=' num2str(svm.theta,'%5.3e') ', C=' num2str(svm.C,'%5.3e') ', err_gen=' num2str(fast_err,'%5.2f') '%, time=' CODES.common.time(time_fast)])
disp(['Using loo,      theta=' num2str(svm1.theta,'%5.3e') ', C=' num2str(svm1.C,'%5.3e') ', err_gen=' num2str(loo_err,'%5.2f') '%, time=' CODES.common.time(time_loo)])
disp(['Using chapelle, theta=' num2str(svm2.theta,'%5.3e') ', C=' num2str(svm2.C,'%5.3e') ', err_gen=' num2str(chapelle_err,'%5.2f') '%, time=' CODES.common.time(time_chapelle)])
disp(['Using auc,      theta=' num2str(svm3.theta,'%5.3e') ', C=' num2str(svm3.C,'%5.3e') ', err_gen=' num2str(auc_err,'%5.2f') '%, time=' CODES.common.time(time_auc)])

[X,Y]=meshgrid(linspace(0,1,100));
Z=reshape(f([X(:) Y(:)]),100,100);
figure('Position',[200 200 500 500])
contour(X,Y,Z,[0 0],'k')
hold on
svm.isoplot('legend',false,'samples',false,'sv',false,'bcol','r')
svm1.isoplot('legend',false,'samples',false,'sv',false,'bcol','b')
svm2.isoplot('legend',false,'samples',false,'sv',false,'bcol','m')
svm3.isoplot('legend',false,'samples',false,'sv',false,'bcol','g')
legend('True','fast','loo','chapelle','auc')

%% References
% <html><ul style="list-style-type:none">
%   <li id="ref_loo"><span style="color:#005fce;">Luntz and Brailovsky
%   (1969)</span>: Luntz A., Brailovsky V., (1969) <i>On estimation of
%   characters obtained in statistical procedure of recognition</i>.
%   Technicheskaya Kibernetica 3(6):6-12</li>
%   <li id="ref_auc"><span style="color:#005fce;">Metz (1978)</span>: Metz
%   C. E., (1978) <i>Basic principles of ROC analysis. Seminars in Nuclear
%   Medicine</i>. Technicheskaya Kibernetica 8(4):283-298 - <a
%   href="http://dx.doi.org/10.1016/S0001-2998(78)80014-2">DOI</a></li>
%   <li id="ref_jaakkola"><span style="color:#005fce;">Jaakkola et al.
%   (1999)</span>: Jaakkola T., Diekhans M., Haussler D., (1999)
%   <i>Using the Fisher kernel method to detect remote protein
%   homologies</i>. In: International Conference on Intelligent Systems for
%   Molecular Biology. 149-158 - <a
%   href="http://www.ncbi.nlm.nih.gov/pubmed/10786297">PMID</a></li>
%   <li id="ref_vap"><span style="color:#005fce;">Vapnik (2000)</span>:
%   Vapnik V., (2000) <i>The nature of statistical learning theory</i>.
%   Springer</li>
%   <li id="ref_cha"><span style="color:#005fce;">Chapelle et al.
%   (2002)</span>: Chapelle O., Vapnik V., Bousquet O., Mukherjee S.,
%   (2002) <i>Choosing multiple parameters for support vector machines</i>.
%   Machine Learning 46(1-3):131-159 - <a 
%   href="http://dx.doi.org/10.1023/A:1012450327387">DOI</a></li>
%   <li id="ref_bas"><span style="color:#005fce;">Basudhar and Missoum
%   (2010)</span>: Basudhar A., Missoum S., (2010) <i>An improved adaptive 
%   sampling scheme for the construction of explicit boundaries</i>.
%   Structural and Multidisciplinary Optimization 42(4):517-529 - <a
%   href="http://dx.doi.org/10.1007/s00158-010-0511-0">DOI</a></li>
%   <li id="ref_peng"><span style="color:#005fce;">Jiang and Missoum
%   (2014)</span>: Jiang P., Missoum S., (2014) <i>Optimal SVM parameter
%   selection for non-separable and unbalanced datasets</i>. Structural and
%   Multidisciplinary Optimization 50(4):523-535 - <a 
%   href="http://dx.doi.org/10.1007/s00158-014-1105-z">DOI</a></li>
% </ul></html>
%%
%%
% <html>Copyright &copy; 2015 Computational Optimal Design of Engineering Systems
% (CODES) Laboratory. University of Arizona.</html>
%%
%
% <html><table style="border: none">
%   <tr style="border: none">
%     <td style="border: none;padding-left: 0px;">
%       <a href ="http://codes.arizona.edu/"><img style="height: 50px;" src ="CODES_logo.png"></a>
%     </td><td style="border: none; vertical-align: middle;padding-left: 10px;">
%       <a href ="http://codes.arizona.edu/"><span style="font-weight:bold;font-family:Arial;font-size: 20px;color: #002147"><span style="color: #AB0520;">C</span>omputational <span style="color: #AB0520;">O</span>ptimal <span style="color: #AB0520;">D</span>esign of<br><span style="color: #AB0520;">E</span>ngineering <span style="color: #AB0520;">S</span>ystems</span></a>
%     </td><td style="border: none;padding-right: 0px;">
%       <a href = "http://www.arizona.edu/"><img style="height: 50px;" src = "AZlogo.png"></a>
%     </td>
%   </tr>
% </table></html>

##### SOURCE END #####
--></body></html>